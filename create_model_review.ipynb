{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/pip:6: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import load_entry_point\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle5 in /home/wiwaaw/.local/lib/python3.8/site-packages (0.0.11)\n",
      "\u001b[31mERROR: Error checking for conflicts.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3109, in _dep_map\n",
      "    return self.__dep_map\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 2902, in __getattr__\n",
      "    raise AttributeError(attr)\n",
      "AttributeError: _DistInfoDistribution__dep_map\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/requirements.py\", line 35, in __init__\n",
      "    parsed = _parse_requirement(requirement_string)\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 64, in parse_requirement\n",
      "    return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 82, in _parse_requirement\n",
      "    url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 120, in _parse_requirement_details\n",
      "    specifier = _parse_specifier(tokenizer)\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_parser.py\", line 217, in _parse_specifier\n",
      "    tokenizer.consume(\"WS\")\n",
      "  File \"/usr/lib/python3.8/contextlib.py\", line 120, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_tokenizer.py\", line 187, in enclosing_tokens\n",
      "    self.raise_syntax_error(\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/_tokenizer.py\", line 165, in raise_syntax_error\n",
      "    raise ParserSyntaxError(\n",
      "pkg_resources.extern.packaging._tokenizer.ParserSyntaxError: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    tinycss2 (>=1.1.0<1.2) ; extra == 'css'\n",
      "             ~~~~~~~~^\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/commands/install.py\", line 543, in _warn_about_conflicts\n",
      "    package_set, _dep_info = check_install_conflicts(to_install)\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/check.py\", line 114, in check_install_conflicts\n",
      "    package_set, _ = create_package_set_from_installed()\n",
      "  File \"/usr/lib/python3/dist-packages/pip/_internal/operations/check.py\", line 53, in create_package_set_from_installed\n",
      "    package_set[name] = PackageDetails(dist.version, dist.requires())\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 2822, in requires\n",
      "    dm = self._dep_map\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3111, in _dep_map\n",
      "    self.__dep_map = self._compute_dependencies()\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3121, in _compute_dependencies\n",
      "    reqs.extend(parse_requirements(req))\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/__init__.py\", line 3174, in __init__\n",
      "    super(Requirement, self).__init__(requirement_string)\n",
      "  File \"/home/wiwaaw/.local/lib/python3.8/site-packages/pkg_resources/_vendor/packaging/requirements.py\", line 37, in __init__\n",
      "    raise InvalidRequirement(str(e)) from e\n",
      "pkg_resources.extern.packaging.requirements.InvalidRequirement: Expected matching RIGHT_PARENTHESIS for LEFT_PARENTHESIS, after version specifier\n",
      "    tinycss2 (>=1.1.0<1.2) ; extra == 'css'\n",
      "             ~~~~~~~~^\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Review Title Review Date  \\\n",
      "0                    This is what Hollywood needs!\\n  2024-02-26   \n",
      "1                           Long live the fighters\\n  2024-02-26   \n",
      "2   Ladies and gentleman.. the PEAK of filmmaking...  2024-02-28   \n",
      "3                    WOW! I need Dune Messiah now.\\n  2024-02-26   \n",
      "4        The Sci-Fi/Fantasy Epic of our Generation\\n  2024-02-26   \n",
      "\n",
      "                                      Review Content  User Rating  \n",
      "0  This is what Hollywood needs. A great story wi...         10.0  \n",
      "1  Phenomenal stuff. I'll probably calm down tomo...          9.0  \n",
      "2  This is the kind of movie that is impossible t...         10.0  \n",
      "3  If you liked or loved the first one, the same ...         10.0  \n",
      "4  Had the pleasure to watch this film in an earl...         10.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('dune_2_reviews.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1066 entries, 0 to 1065\n",
      "Data columns (total 4 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Review Title    1066 non-null   object \n",
      " 1   Review Date     1066 non-null   object \n",
      " 2   Review Content  1066 non-null   object \n",
      " 3   User Rating     1056 non-null   float64\n",
      "dtypes: float64(1), object(3)\n",
      "memory usage: 33.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Title       0\n",
      "Review Date        0\n",
      "Review Content     0\n",
      "User Rating       10\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1056.000000\n",
      "mean        8.579545\n",
      "std         2.148805\n",
      "min         1.000000\n",
      "25%         8.000000\n",
      "50%        10.000000\n",
      "75%        10.000000\n",
      "max        10.000000\n",
      "Name: User Rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['User Rating'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Review Content</th>\n",
       "      <th>User Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is what Hollywood needs!\\n</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>This is what Hollywood needs. A great story wi...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Long live the fighters\\n</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>Phenomenal stuff. I'll probably calm down tomo...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ladies and gentleman.. the PEAK of filmmaking...</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>This is the kind of movie that is impossible t...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WOW! I need Dune Messiah now.\\n</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>If you liked or loved the first one, the same ...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Sci-Fi/Fantasy Epic of our Generation\\n</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>Had the pleasure to watch this film in an earl...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Review Title Review Date  \\\n",
       "0                    This is what Hollywood needs!\\n  2024-02-26   \n",
       "1                           Long live the fighters\\n  2024-02-26   \n",
       "2   Ladies and gentleman.. the PEAK of filmmaking...  2024-02-28   \n",
       "3                    WOW! I need Dune Messiah now.\\n  2024-02-26   \n",
       "4        The Sci-Fi/Fantasy Epic of our Generation\\n  2024-02-26   \n",
       "\n",
       "                                      Review Content  User Rating  \n",
       "0  This is what Hollywood needs. A great story wi...         10.0  \n",
       "1  Phenomenal stuff. I'll probably calm down tomo...          9.0  \n",
       "2  This is the kind of movie that is impossible t...         10.0  \n",
       "3  If you liked or loved the first one, the same ...         10.0  \n",
       "4  Had the pleasure to watch this film in an earl...         10.0  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PreProcessing & Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters, numbers, and punctuations\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Join the tokens back into a single string\n",
    "    cleaned_text = ' '.join(filtered_tokens)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review Content'] = df['Review Content'].apply(clean_text)\n",
    "df['Review Title'] = df['Review Title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Review Date</th>\n",
       "      <th>Review Content</th>\n",
       "      <th>User Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hollywood needs</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>hollywood needs great story great directorprod...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>long live fighters</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>phenomenal stuff ill probably calm tomorrow ri...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ladies gentleman peak filmmaking</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>kind movie impossible justice talking kind exp...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow need dune messiah</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>liked loved first one apply one personally lov...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scififantasy epic generation</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>pleasure watch film early screening completely...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Review Title Review Date  \\\n",
       "0                   hollywood needs  2024-02-26   \n",
       "1                long live fighters  2024-02-26   \n",
       "2  ladies gentleman peak filmmaking  2024-02-28   \n",
       "3             wow need dune messiah  2024-02-26   \n",
       "4      scififantasy epic generation  2024-02-26   \n",
       "\n",
       "                                      Review Content  User Rating  \n",
       "0  hollywood needs great story great directorprod...         10.0  \n",
       "1  phenomenal stuff ill probably calm tomorrow ri...          9.0  \n",
       "2  kind movie impossible justice talking kind exp...         10.0  \n",
       "3  liked loved first one apply one personally lov...         10.0  \n",
       "4  pleasure watch film early screening completely...         10.0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Review Title': 'title', 'Review Date': 'date', 'Review Content': 'review', 'User Rating': 'rating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hollywood needs</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>hollywood needs great story great directorprod...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>long live fighters</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>phenomenal stuff ill probably calm tomorrow ri...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ladies gentleman peak filmmaking</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>kind movie impossible justice talking kind exp...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wow need dune messiah</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>liked loved first one apply one personally lov...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>scififantasy epic generation</td>\n",
       "      <td>2024-02-26</td>\n",
       "      <td>pleasure watch film early screening completely...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              title        date  \\\n",
       "0                   hollywood needs  2024-02-26   \n",
       "1                long live fighters  2024-02-26   \n",
       "2  ladies gentleman peak filmmaking  2024-02-28   \n",
       "3             wow need dune messiah  2024-02-26   \n",
       "4      scififantasy epic generation  2024-02-26   \n",
       "\n",
       "                                              review  rating  \n",
       "0  hollywood needs great story great directorprod...    10.0  \n",
       "1  phenomenal stuff ill probably calm tomorrow ri...     9.0  \n",
       "2  kind movie impossible justice talking kind exp...    10.0  \n",
       "3  liked loved first one apply one personally lov...    10.0  \n",
       "4  pleasure watch film early screening completely...    10.0  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing value, replace with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>snooze fest</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>movie wasnt hours long say hours id probably g...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>epic novelepic adaptation</td>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>since first part dune paul timothee chalamet m...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>cant fiction wont fool us</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>first let tell walked cinema thinking watched ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>villeneuves offering solidifies great piece sc...</td>\n",
       "      <td>2024-03-03</td>\n",
       "      <td>spurred revenge paul embraces fremen ways must...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>ruin</td>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>ruin suspect better ruin one unfortunately ima...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>great movie better first one serie still bette...</td>\n",
       "      <td>2024-03-03</td>\n",
       "      <td>includes spoilers want read booksthis film rem...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>questionable casting decisions</td>\n",
       "      <td>2024-03-03</td>\n",
       "      <td>find perplexed casting choices film particular...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>dune part two boring way long</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>welljust got see dune part two beautiful movie...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>people love nowadays</td>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>considered masterpiece many people direction v...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>scifi doesnt watch scifi</td>\n",
       "      <td>2024-02-29</td>\n",
       "      <td>wife isnt stretch imagination scifi fan loved ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title        date  \\\n",
       "55                                         snooze fest  2024-03-01   \n",
       "149                          epic novelepic adaptation  2024-03-05   \n",
       "384                          cant fiction wont fool us  2024-02-28   \n",
       "403  villeneuves offering solidifies great piece sc...  2024-03-03   \n",
       "544                                               ruin  2024-03-04   \n",
       "558  great movie better first one serie still bette...  2024-03-03   \n",
       "573                     questionable casting decisions  2024-03-03   \n",
       "667                      dune part two boring way long  2024-02-28   \n",
       "771                               people love nowadays  2024-03-04   \n",
       "903                           scifi doesnt watch scifi  2024-02-29   \n",
       "\n",
       "                                                review  rating  \n",
       "55   movie wasnt hours long say hours id probably g...     NaN  \n",
       "149  since first part dune paul timothee chalamet m...     NaN  \n",
       "384  first let tell walked cinema thinking watched ...     NaN  \n",
       "403  spurred revenge paul embraces fremen ways must...     NaN  \n",
       "544  ruin suspect better ruin one unfortunately ima...     NaN  \n",
       "558  includes spoilers want read booksthis film rem...     NaN  \n",
       "573  find perplexed casting choices film particular...     NaN  \n",
       "667  welljust got see dune part two beautiful movie...     NaN  \n",
       "771  considered masterpiece many people direction v...     NaN  \n",
       "903  wife isnt stretch imagination scifi fan loved ...     NaN  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['rating'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan(value):\n",
    "    if pd.isnull(value):\n",
    "        return df['rating'].mean()\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "df['rating'] = df['rating'].apply(replace_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['review', 'rating']]\n",
    "df['sentiment'] = df['rating'].apply(lambda x: 'positive' if x > 5 \n",
    "                                    else 'negative' if x < 5\n",
    "                                    else 'neutral')\n",
    "df = df[['review', 'rating', 'sentiment']]\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>following events first dune film paul atreides...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review dune part two cinemas rating checked ra...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>second movie dune epic actors costumes scenes ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>awesome stunning film follows spirit books eve...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>masterpiece need watch carefully every scene d...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating sentiment\n",
       "0  following events first dune film paul atreides...    10.0  positive\n",
       "1  review dune part two cinemas rating checked ra...    10.0  positive\n",
       "2  second movie dune epic actors costumes scenes ...    10.0  positive\n",
       "3  awesome stunning film follows spirit books eve...    10.0  positive\n",
       "4  masterpiece need watch carefully every scene d...    10.0  positive"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Review\n",
    "- Transform the Review text into a series of numbers using the tokenizer. This process establishes a list of the distinct words found in the Review text and assigns a distinct integer value to each word. Utilize the pad_sequences method from Keras to guarantee uniform length for all review sequences.\n",
    "- The Tokenizer provided by Keras is a convenient way to convert text data into sequences of integers. It performs tokenization, which splits the text into words, and then assigns a unique integer to each word. This process is essential for neural network models to process text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=5000, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(df['review'])\n",
    "word_index = tokenizer.word_index\n",
    "sequences = tokenizer.texts_to_sequences(df['review'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=100, truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `oov_token='<OOV>'` parameter specifies that any out-of-vocabulary words encountered during tokenization should be replaced with the <OOV> token. This helps handle unseen words during model inference or when processing new data that may contain words not seen during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_labels = pd.get_dummies(df['sentiment']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    963\n",
       "negative     71\n",
       "neutral      32\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_neutral = df.loc[df[\"sentiment\"] == \"neutral\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>dune part two unfortunately nothing aboveavera...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>went blind aware hype praise giving fair chanc...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>many times havent seen movies people try build...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>sure cinematography wonderful sound breathtaki...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>shame first movie accurate loyal book except h...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  rating sentiment\n",
       "29   dune part two unfortunately nothing aboveavera...     5.0   neutral\n",
       "60   went blind aware hype praise giving fair chanc...     5.0   neutral\n",
       "88   many times havent seen movies people try build...     5.0   neutral\n",
       "128  sure cinematography wonderful sound breathtaki...     5.0   neutral\n",
       "147  shame first movie accurate loyal book except h...     5.0   neutral"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_neutral.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset\n",
    "Splitting the Dataset Into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn to randomly split the dataset into training and testing sets. The training set is to train the model to classify the sentiments of the reviews. The test set is to access how good the model is at classifying new unseen reviews.\n",
    "\n",
    "The dataset split size is 0.2. This means that 80% of the data will train the model. And the rest 20% will test the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(padded_sequences, sentiment_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a neural network with six layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **First layer**: Embedding layer. This layer learns a dense representation of words in the vocabulary.\n",
    "- **Second layer**: Conv1D layer with 64 filters and a kernel size of 5. This layer performs convolution operations on the input sequences, using a small sliding window of size 5.\n",
    "- **Third layer**: GlobalMaxPooling1D. Reduces the sequence of feature maps to a single vector. It takes the maximum value over each feature map.\n",
    "- **Fourth layer**: Dense. Performs a linear transformation on the input vector. \n",
    "- **Fifth layer**: Dropout. Randomly sets a fraction of the input units to 0 during training. This helps prevent overfitting.\n",
    "- **Sixth layer**: Output layer. Converts the output to a probability distribution over the three possible classes: positive, neutral, and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 100)          500000    \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 96, 64)            32064     \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 64)               0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 534,243\n",
      "Trainable params: 534,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(5000, 100, input_length=100))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 16ms/step - loss: 0.7781 - accuracy: 0.8462 - val_loss: 0.4825 - val_accuracy: 0.8972\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.4570 - accuracy: 0.9049 - val_loss: 0.4140 - val_accuracy: 0.8972\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.3873 - accuracy: 0.9049 - val_loss: 0.4065 - val_accuracy: 0.8972\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.3726 - accuracy: 0.9049 - val_loss: 0.4007 - val_accuracy: 0.8972\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 0s 13ms/step - loss: 0.3235 - accuracy: 0.9049 - val_loss: 0.3947 - val_accuracy: 0.8972\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2835 - accuracy: 0.9061 - val_loss: 0.3891 - val_accuracy: 0.8972\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.2229 - accuracy: 0.9108 - val_loss: 0.3804 - val_accuracy: 0.8972\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.1666 - accuracy: 0.9519 - val_loss: 0.3933 - val_accuracy: 0.8972\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.1178 - accuracy: 0.9671 - val_loss: 0.3950 - val_accuracy: 0.8972\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 0s 12ms/step - loss: 0.0961 - accuracy: 0.9730 - val_loss: 0.4440 - val_accuracy: 0.8972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fce70785ac0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the accuracy of the sentiment predictor, we would compare the predicted sentiment labels `y_pred` with the actual sentiment labels `y_test`. Since this is a multi-class classification problem, we can use the `accuracy_score` function from scikit-learn's metrics module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `model.predict()` method to predict the sentiment labels for the test set. Calculate the accuracy score using the `accuracy_score()` function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.897196261682243\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict(x_test), axis=-1)\n",
    "print(\"Accuracy:\", accuracy_score(np.argmax(y_test, axis=-1), y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Model\n",
    "Save the model using the `model.save()` method. Use pickle to serialize and save the tokenizer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('sentiment_analysis_model.h5')\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "model = keras.models.load_model('sentiment_analysis_model.h5')\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    # Tokenize and pad the input text\n",
    "    text_sequence = tokenizer.texts_to_sequences([text])\n",
    "    text_sequence = pad_sequences(text_sequence, maxlen=100)\n",
    "\n",
    "    # Make a prediction using the trained model\n",
    "    predicted_rating = model.predict(text_sequence)[0]\n",
    "    print(predicted_rating[2])\n",
    "    if np.argmax(predicted_rating) == 0:\n",
    "        return 'Negative'\n",
    "    elif np.argmax(predicted_rating) == 1:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict your own review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6532788\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "text_input = \"This movie is great, I loved it\"\n",
    "predicted_sentiment = predict_sentiment(text_input)\n",
    "print(predicted_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Time Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Speed (seconds): 0.055696725845336914\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Example text for prediction\n",
    "example_text = \"This movie is great, I loved it!\"\n",
    "\n",
    "# Tokenize and pad the input text\n",
    "text_sequence = tokenizer.texts_to_sequences([example_text])\n",
    "text_sequence = pad_sequences(text_sequence, maxlen=100)\n",
    "\n",
    "# Measure the time taken for prediction\n",
    "start_time = time.time()\n",
    "predicted_rating = model.predict(text_sequence)\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate inference speed\n",
    "inference_time = end_time - start_time\n",
    "print(\"Inference Speed (seconds):\", inference_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps for Improvement\n",
    "\n",
    "- Considering the dataset's imbalance, the next step is to address this issue by implementing various balancing techniques. The specific technique to be used is yet to be determined after further evaluation.\n",
    "- Exploring classic algorithms like Support Vector Machines (SVM) or Naïve Bayes could be beneficial. These algorithms are well-established for classification tasks and may provide valuable insights alongside the Neural Network approach.\n",
    "- Given that the task is defined as multiclass classification, the model's output will be a vector containing probabilities for each class. Future iterations may involve exploring binary classification for a more focused analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
